series: xenial
applications:
  "hadoop-plugin":
    charm: "cs:hadoop-plugin-27"
  "hadoop-resourcemanager":
    charm: "cs:hadoop-resourcemanager-29"
    num_units: 1
    to:
      - "1"
  "hadoop-namenode":
    charm: "cs:hadoop-namenode-27"
    num_units: 1
    to:
      - "1"
  zeppelin:
    charm: "cs:zeppelin-28"
    num_units: 1
    expose: true
    to:
      - "1"
  spark:
    charm: "cs:spark-52"
    num_units: 1
    options:
      spark_bench_enabled: true
      spark_execution_mode: "yarn-client"
    to:
      - "0"
  "hadoop-slave":
    charm: "cs:hadoop-slave-28"
    num_units: 1
    to:
      - "0"
  "writedata-job":
    charm: "/home/ubuntu/local_charms/xenial/spark-job"
    options:
      job_location: "https://raw.githubusercontent.com/Qrama/spark-bundle/master/jobs/writedata.py"
  "transformdata-job":
    charm: "/home/ubuntu/local_charms/xenial/spark-job"
    options:
      job_location: "https://raw.githubusercontent.com/Qrama/spark-bundle/master/jobs/transformdata.py"
  "tengu-notebook":
    charm: "/home/ubuntu/local_charms/xenial/notebook-deployer"
relations:
  - - "hadoop-namenode:datanode"
    - "hadoop-slave:namenode"
  - - "hadoop-plugin:namenode"
    - "hadoop-namenode:namenode"
  - - "spark:hadoop"
    - "hadoop-plugin:hadoop-plugin"
  - - "hadoop-namenode:namenode"
    - "hadoop-resourcemanager:namenode"
  - - "zeppelin:spark"
    - "spark:client"
  - - "hadoop-resourcemanager:nodemanager"
    - "hadoop-slave:resourcemanager"
  - - "hadoop-plugin:resourcemanager"
    - "hadoop-resourcemanager:resourcemanager"
  - - "spark:juju-info"
    - "transform-data:spark"
  - - "spark:juju-info"
    - "writedata-job:spark"
  - - "zeppelin:juju-info"
    - "tengu-notebook:zeppelin"
machines:
  "0":
    series: xenial
    constraints: "arch=amd64 cpu-cores=1 cpu-power=138 mem=1700 root-disk=10240"
  "1":
    series: xenial
    constraints: "arch=amd64 cpu-cores=1 cpu-power=138 mem=1700 root-disk=10240"
